\subsection{Обзор литературы}

\subsubsection{Общие сведения о диффузионных моделях}
\par
Долго лидирующие на поприще генерации изображений генеративно-состязательные сети обладают набором проблем, с которыми боролось и продолжает бороться научное сообщество. Основными проблемами, сохранившимися до сих пор, являются нестабильность обучения \cite{kodali2017convergence}, решаемая с помощью спектральной нормализации \cite{miyato2018spectral}, контролирующей константу Липшица, вводя ограничение весов, для стабилизации обучения дискриминатора; Mode Collapse \cite{thanhtung2020catastrophic}. Последняя является одной из главных проблем моделей такого типа. Проблема заключается в том, что в процессе обучения генератор приходит к состоянию, при котором генерируется лишь ограченный (существенно меньший оригинального пространства изображений) набор выходов. Предлагаемые решения этой проблемы -- WGAN \cite{arjovsky2017wasserstein} (авторы используют метрику Вассерштейна внутри лосс-функции, тем самым мотивируя дискриминатор выявлять повторяющие выходы, в которых стабилизировался генератор) и UGAN \cite{metz2017unrolled} (также адаптация функции потерь, однако теперь с оценкой выходов генератора на основе предсказаний будущих версий дискриминатора).

\par
В отличие от генеративно-состязательных сетей эти же проблемы не свойственны новому классу моделей -- диффузионным моделям. В оригинальной статье \cite{sohldickstein2015deep} авторы утилизируют идею из статистической термодинамики. Главной целью авторы видят определение двух процессов: итеративный диффузный процесс, который преобразует любое комплекное распределение данных в более простое и контролируемое, постепенно уменьшая SNR (signal-to-noise ratio), а также параметризованный обратный диффузионный процесс, обучаемый итеративно моделировать целевое распределение. В статье \cite{ho2020denoising} объемно исследуется использование диффузионных моделей для генерации изображений. Оригинально диффузионные модели базируются на методе моделирования динамики молекулярных систем -- динамике Ланжевена. 

\par
Рассмотрим набор данных из сложно контролируемого целевого распределения: $X = (x_1, \ldots, x_n)$. Построим прямой процесс диффузии, постепенно зашумляющий данные из целевого распределения (уменьшая SNR).
\[
    \begin{array}{c}
        x_i^0 \to x_i^1 \to \ldots \to x_i^T\\
        x_i^{t+1} = \sqrt{1-\beta}\cdot x_i^t + \sqrt{\beta}\cdot \varepsilon, \hfill \varepsilon \sim \mathcal{N}(\varepsilon| \ 0, \ I)
    \end{array}
\]
где $\beta$ -- скорость диффузии, $x_i$ -- семпл из выборки. Это также можно записать в виде:
\[
    q_{t+1} (x^{t+1}|x^t) = \mathcal{N}(x^{t+1} | \sqrt{1 - \beta}x^T, \beta)\\
\]
Причем можно также получить явное выражение для $q_T (x^{t+1} | x^0)$:
\[
    q_T (x^{t+1} | x^0) = \mathcal{N}(x^{t+1}| \ \sqrt{\overline{\alpha}_{t+1}}x^0, \ (1 - \overline{\alpha}_{t+1}I)),
\]
где $\overline{\alpha}_{t+1} = (1 - \beta)^{t+1}$. При бесконечной диффузии $(T >> 1):$

\[
    \overline{\alpha}_T \to 0, \hspace*{1.5cm} q_T(x^T \ | \ x^0) \sim \mathcal{N}(x^T| \ 0, I)  
\]



\par
Пусть $x_0 \to x_1 \to \ldots \to x_T$ -- однородная Марковская цепь, порожденная динамикой Ланжевена. Запишем динамику Ланжевена для произвольного распределения $p(x)$:

\begin{equation}
    \label{eq:Langevene}
    x^{t+1} = x^t + \varkappa \left(\dfrac{1}{2} \dfrac{\partial }{\partial x} \log p(x) + \dfrac{\varepsilon}{\sqrt{\varkappa}}\right), \hspace*{1.5cm} \varepsilon \sim \mathcal{N}(\varepsilon | 0,\ I)
\end{equation}
Важнейшим свойством динамики Ланжевена является сохранение плотности, т.е. $x^t \sim p(x) \Rightarrow x^{t+1} \sim p(x)$. (см. \hyperref[AppendixA]{ПРИЛОЖЕНИЕ 1}). 
Процедура \ref{eq:Langevene} представляет собой градиентный подъем, который направлен на нахождение моды распределения, однако, что является большим преимуществом перед генеративно-состязательными сетями: происходит зашумление градиента, что релаксирует высокие значения плотности распределения. 

\par

% ! дописать


\subsubsection{Обуславливаемые диффузионные модели (Conditioned diffusion models)}
\par
% ! дописать
В статье \cite{rombach2022highresolution} предлагается диффузионный процесс не в пространстве изображений, а в пространстве эмбеддингов, полученных с помощью автоэнкодера (VQ-VAE). Так же в предлагаемой U-Net подобной сети авторы предлагают условное обучение (возможность, обуславливать изображения, например, на текст). В статье \cite{sohldickstein2015deep} предлагается постепенное зашумление 

% ! дописать
В \cite{ruiz2023dreambooth} предлагается использование концептов. 




\subsubsection{Обучение моделей}
\par

\subsubsection{Задача замены лиц (Face swap)}

\par
